{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WOmj4d607i6"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1663441448995,
     "user": {
      "displayName": "safwan wshah",
      "userId": "17703726182199816036"
     },
     "user_tz": 240
    },
    "id": "luUjl8vV07i-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "from scipy.stats import randint as sp_randint\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGnSVXfq07i_"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "The Scikit-Learn library uses NumPy arrays in its implementation, we will use pandas to load *.csv files then convert it to NumPy.\n",
    "\n",
    "This dataset provided by National Institute of Diabetes and Digestive and Kidney Diseases; The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "refer to https://www.kaggle.com/uciml/pima-indians-diabetes-database for more details ...\n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) \n",
    "\n",
    "Note: In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "#### Task --> for patients given attributes discribed above, is she diabetic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and Columns are:  (768, 9)\n",
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 268)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the file\n",
    "data = pd.read_csv(\"./data/diabetes.csv\")\n",
    "\n",
    "# printing the length of data - (rows x columns)\n",
    "print(\"The number of rows and Columns are: \", data.shape)\n",
    "\n",
    "# name of columns in the data\n",
    "print(data.columns)\n",
    "\n",
    "# lets see the most frequent target class\n",
    "len(data[data['Outcome']==0]), len(data[data['Outcome']==1]), \n",
    "# therefore the most frequenct class is 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the data into numpy matrix\n",
    "dataset = data.values\n",
    "\n",
    "# separating the data into X and Y - (features, target)\n",
    "X = dataset[:, 0:8]\n",
    "\n",
    "Y = dataset[:, -1].reshape((768,1)) # it is better no to reshape it - Otherwise you have to flatten it later - I just reshape it to spice the things\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sBJfPCw07jB"
   },
   "source": [
    "## Data Normalization\n",
    "As you know, the majority of gradient based methods are highly sensitive to data scaling. Therefore, before running an algorithm, we are going to perform either normalization or standardization.\n",
    "\n",
    "refer to http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing for more infromation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.9736822155037493\n",
      "-4.060473872668307 6.65283937836846\n"
     ]
    }
   ],
   "source": [
    "# normalizing the data attributes\n",
    "normalized_x = preprocessing.normalize(X)\n",
    "\n",
    "# Center to the mean and component wise scale to a unit variance\n",
    "standarized_x = preprocessing.scale(X)\n",
    "\n",
    "# lets print the max and min values of above normalized and standarized data\n",
    "print(np.min(normalized_x), np.max(normalized_x))\n",
    "print(np.min(standarized_x), np.max(standarized_x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2MkfRvH07jC"
   },
   "source": [
    "## Data split \n",
    "Split the data into training and testing, 80% for training and 20% for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(standarized_x, Y, train_size=0.80, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOf7UZpx07jE"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "use Logistic Regression for binary classificaiton in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is  0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "# lets define the model\n",
    "model = LogisticRegression(solver ='liblinear')\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, Y_train.ravel())\n",
    "\n",
    "# lets make predictions using the trained model on unseen data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# lets measure the performance\n",
    "acc = accuracy_score(Y_test, predicted)\n",
    "\n",
    "# report the results\n",
    "print(\"The accuracy is \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7kJ_lww07jG"
   },
   "source": [
    "What if we build a dump classifier that always prediect the highest accuracy ?\n",
    "\n",
    "accuracy that could be achieved by always by predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1663441509094,
     "user": {
      "displayName": "safwan wshah",
      "userId": "17703726182199816036"
     },
     "user_tz": 240
    },
    "id": "hAI1hiDs07jG",
    "outputId": "c8e9fc94-b6ff-4400-8dbe-1763c8ea9a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of zeros =  0.6428571428571428 percentage of ones =  0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "# because y_test only contains ones and zeros, we can simply calculate the mean = percentage of ones\n",
    "class_one_percentage = Y_test.mean()\n",
    "print (\"percentage of zeros = \", 1 - class_one_percentage, \"percentage of ones = \", class_one_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvCfL6iR07jH"
   },
   "source": [
    "This means that a dumb model that always predicts 0 would be right 64.2% of the time\n",
    "\n",
    "This shows how classification accuracy is not that good as it's close to a dumb model\n",
    "\n",
    "\n",
    "It's a good way to know the minimum we should achieve with our models\n",
    "\n",
    "#### Notes:\n",
    "- Classification accuracy is the easiest classification metric to understand\n",
    "- But, it does not tell you the underlying distribution of response values\n",
    "- We examine by calculating the dump classifer accuracy\n",
    "- And, it does not tell you what \"types\" of errors your classifier is making\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples are:  154\n",
      "[[79 20]\n",
      " [18 37]]\n"
     ]
    }
   ],
   "source": [
    "# lets calculate the confusion matrix values\n",
    "# IMPORTANT: first argument will always be the True values and second argument is predicted values\n",
    "# lets print the total number of test samples\n",
    "print(\"Number of test samples are: \", len(Y_test))\n",
    "\n",
    "# getting the confusion matrix\n",
    "confusion = metrics.confusion_matrix(Y_test, predicted)\n",
    "\n",
    "# lets display it\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzjTIiVO07jH"
   },
   "source": [
    "True Positives (TP): we correctly predicted that they do have diabetes = 79\n",
    "\n",
    "True Negatives (TN): we correctly predicted that they don't have diabetes = 37\n",
    "\n",
    "False Positives (FP): we incorrectly predicted that they do have diabetes = 18\n",
    "\n",
    "Falsely predict positive\n",
    "\n",
    "False Negatives (FN): we incorrectly predicted that they don't have diabetes = 20\n",
    "\n",
    "Falsely predict negative\n",
    "\n",
    "Based on these numbers you can calculates recall, accuracy, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of these metrics based on 0.5 threshold ....\n",
      "Accuracy =  0.7532467532467533\n",
      "sensitivity =  0.8144329896907216\n",
      "specificity =  0.6491228070175439\n",
      "false_positive_rate =  0.3508771929824561\n",
      "precision =  0.797979797979798\n",
      "recall =  0.8144329896907216\n"
     ]
    }
   ],
   "source": [
    "TN = confusion[1, 1]\n",
    "TP = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "print (\"All of these metrics based on 0.5 threshold ....\")\n",
    "# use float to perform true division, not integer division\n",
    "print(\"Accuracy = \", (TP + TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity = \",sensitivity)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"specificity = \",specificity)\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(\"false_positive_rate = \",false_positive_rate)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(\"precision = \", precision)\n",
    "\n",
    "print(\"recall = \", sensitivity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzew_qN907jI"
   },
   "source": [
    "## Logistic Regression with Polynomials\n",
    "\n",
    "use Logistic Regression for binary classificaiton after mapping the feature to different Polynomials degrees. plus use regularizer to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Poy X Train/Test is:  (614, 44) (154, 44)\n",
      "THe accuracy is:  0.6558441558441559\n"
     ]
    }
   ],
   "source": [
    "# lets define the model, set regularizer parameter C to 0.0001\n",
    "model = LogisticRegression(C = 0.0001, solver='liblinear')\n",
    "\n",
    "# deinfe Polynomial transformation\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "\n",
    "# lets map the features\n",
    "poly_X_Train = poly.fit_transform(X_train)\n",
    "poly_X_test = poly.fit_transform(X_test)\n",
    "\n",
    "# printing their shapes\n",
    "print(\"The shape of Poy X Train/Test is: \", poly_X_Train.shape, poly_X_test.shape)\n",
    "\n",
    "# We need to normalize the data at this point again\n",
    "# fit the model with the mapped features\n",
    "model.fit(poly_X_Train, Y_train.ravel())\n",
    "\n",
    "# lets predict the model\n",
    "predicted = model.predict(poly_X_test)\n",
    "\n",
    "# Lets compute the accuracy\n",
    "acc = accuracy_score(Y_test.ravel(), predicted)\n",
    "\n",
    "# lets report the results\n",
    "print(\"THe accuracy is: \", acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ_v8Q6707jI"
   },
   "source": [
    "In the previous cell we used all the holdout method. it is much better to use cross validation. for this small dataset I\n",
    "suggest using k-fold with K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft_Directory\\anaconda\\envs\\reid\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:174: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics Classification Report is Given as \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.80       500\n",
      "         1.0       0.64      0.62      0.63       268\n",
      "\n",
      "    accuracy                           0.74       768\n",
      "   macro avg       0.72      0.71      0.72       768\n",
      "weighted avg       0.74      0.74      0.74       768\n",
      "\n",
      "The confusion matrix scores are: \n",
      "\n",
      "All of these metrics based on 0.5 threshold ....\n",
      "Accuracy =  0.7434895833333334\n",
      "sensitivity =  0.7988165680473372\n",
      "specificity =  0.6360153256704981\n",
      "false_positive_rate =  0.36398467432950193\n",
      "precision =  0.81\n",
      "recall =  0.7988165680473372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "# lets define the model. set regularizer parameter C to 0.0001\n",
    "model = LogisticRegression(C=0.0001, solver='liblinear', penalty='l2')\n",
    "\n",
    "# define the polynomial transformation\n",
    "poly = PolynomialFeatures(degree=6, include_bias=False)\n",
    "\n",
    "# map the features\n",
    "poly_X = poly.fit_transform(X)\n",
    "standarized_poly_x = preprocessing.scale(poly_X)\n",
    "\n",
    "# lets use the cross validation for prediction\n",
    "y_predict = cross_val_predict(model, standarized_poly_x, Y.ravel(), cv=5, verbose=1)\n",
    "\n",
    "print(\"The metrics Classification Report is Given as \\n\", metrics.classification_report(Y.ravel(), y_predict))\n",
    "confusion =  metrics.confusion_matrix(Y.ravel(), y_predict)\n",
    "print(\"The confusion matrix scores are: \\n\",)\n",
    "\n",
    "# lets extract the TP, TN, FP, FN from above confusion matrix\n",
    "TP = confusion[0, 0]\n",
    "TN = confusion[1, 1]\n",
    "FN = confusion[1, 0]\n",
    "FP = confusion[0, 1]\n",
    "\n",
    "# lets compute the performance metrics\n",
    "print (\"All of these metrics based on 0.5 threshold ....\")\n",
    "# use float to perform true division, not integer division\n",
    "print(\"Accuracy = \", (TP + TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity = \",sensitivity)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"specificity = \",specificity)\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(\"false_positive_rate = \",false_positive_rate)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(\"precision = \", precision)\n",
    "\n",
    "print(\"recall = \", sensitivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrjZKhyu07jJ"
   },
   "source": [
    "Apply grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hyperparameters are:\n",
      " {'C': array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01]), 'penalty': ['l1', 'l2']}\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft_Directory\\anaconda\\envs\\reid\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty is:  l1\n",
      "Best C is:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft_Directory\\anaconda\\envs\\reid\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "C = 10.**np.arange(-7, 2)\n",
    "penalty = ['l1', 'l2']\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "print(' Hyperparameters are:\\n', hyperparameters)\n",
    "\n",
    "# lets build the logistic regression model\n",
    "logistic = LogisticRegression(solver='liblinear')\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=1)\n",
    "best_model = clf.fit(standarized_poly_x, Y.ravel())\n",
    "\n",
    "# lets get the best parameters\n",
    "print(\"Best Penalty is: \", best_model.best_estimator_.get_params()['penalty'])\n",
    "print(\"Best C is: \", best_model.best_estimator_.get_params()['C'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "# lets use the best model from above\n",
    "y_predicted = cross_val_predict(best_model, standarized_poly_x, Y.ravel(), cv=5)\n",
    "\n",
    "# lets print the model performance metrics\n",
    "print(\"Metrics Classification Report:\", metrics.classification_report(Y.ravel(), y_predicted))\n",
    "print(\"Confusion Metrics is: \", metrics.confusion_matrix(Y.ravel(), y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the remaining performance metrics\n",
    "TP = confusion[0, 0]\n",
    "TN = confusion[1, 1]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "print (\"All of these metrics based on 0.5 threshold ....\")\n",
    "# use float to perform true division, not integer division\n",
    "print(\"Accuracy = \", (TP + TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"sensitivity = \",sensitivity)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"specificity = \",specificity)\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(\"false_positive_rate = \",false_positive_rate)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(\"precision = \", precision)\n",
    "\n",
    "print(\"recall = \", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UT1kYIS807jK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
